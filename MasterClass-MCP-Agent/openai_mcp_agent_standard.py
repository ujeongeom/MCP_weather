#!/usr/bin/env python3
"""
OpenAI Agents SDK with MCP Extension
í‘œì¤€ OpenAI APIë¥¼ ì‚¬ìš©í•˜ëŠ” MCP Agent
"""

import asyncio
import os
import json
from typing import Any, Dict, List, Optional
from datetime import datetime
from contextlib import AsyncExitStack

from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionMessageParam, ChatCompletionMessageToolCall

from mcp.client.stdio import stdio_client
from mcp import StdioServerParameters, ClientSession
from mcp.types import Tool as MCPTool, TextContent


class OpenaiMcpAgentStandard:
    """
    MCP ì„œë²„ì™€ í†µì‹ í•˜ê³  í‘œì¤€ OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸.
    mcp_servers.json ì„¤ì • íŒŒì¼ì„ í†µí•´ ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    """

    def __init__(self, config: Dict[str, Any]):
        self.client = AsyncOpenAI(
            api_key=config["api_key"],
        )
        self.model_name = config["model_name"]
        self.exit_stack = AsyncExitStack()
        self.sessions: Dict[str, ClientSession] = {}
        self.messages: List[ChatCompletionMessageParam] = []

    async def connect_to_servers(self, config_path: str = "mcp_servers.json"):
        """mcp_servers.json ì„¤ì • íŒŒì¼ì„ ì½ì–´ ëª¨ë“  MCP ì„œë²„ì— ì—°ê²°í•©ë‹ˆë‹¤."""
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                server_configs = json.load(f).get("mcpServers", {})
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"âŒ '{config_path}' íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return

        for server_name, config in server_configs.items():
            if config.get("transport") == "stdio":
                print(f"'{server_name}' ì„œë²„ì— ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤... (stdio)")
                server_params = StdioServerParameters(
                    command=config["command"],
                    args=config.get("args", []),
                    env=config.get("env")
                )
                try:
                    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
                    _, write = stdio_transport
                    session = await self.exit_stack.enter_async_context(ClientSession(stdio_transport[0], write))
                    await session.initialize()
                    self.sessions[server_name] = session
                    print(f"âœ… '{server_name}' ì„œë²„ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"âŒ '{server_name}' ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            # TODO: Add support for other transports like 'sse' if needed

    async def run_query(self, query: str) -> str:
        if not self.sessions:
            raise RuntimeError("ì—°ê²°ëœ MCP ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € connect_to_servers()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        self.messages.append({"role": "user", "content": query})

        # ëª¨ë“  ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        all_tools = []
        for session in self.sessions.values():
            try:
                list_tools_response = await session.list_tools()
                all_tools.extend(list_tools_response.tools)
            except Exception as e:
                print(f"âš ï¸ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        
        tools_for_openai = [self._format_tool_for_openai(tool) for tool in all_tools]

        while True:
            response = await self.client.chat.completions.create(
                model=self.model_name,
                messages=self.messages,
                tools=tools_for_openai,
                tool_choice="auto",
            )
            response_message = response.choices[0].message

            if not response_message.tool_calls:
                self.messages.append(response_message)
                return response_message.content or "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            self.messages.append(response_message)
            
            for tool_call in response_message.tool_calls:
                tool_result = await self._execute_tool_call(tool_call, all_tools)
                self.messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": tool_call.function.name,
                    "content": tool_result,
                })

    async def _execute_tool_call(self, tool_call: ChatCompletionMessageToolCall, available_tools: List[MCPTool]) -> str:
        tool_name = tool_call.function.name
        
        # ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” ì˜¬ë°”ë¥¸ ì„¸ì…˜ ì°¾ê¸°
        target_session = None
        for session in self.sessions.values():
            try:
                # ê°„ë‹¨í•œ ë°©ë²•: ì„¸ì…˜ì´ ë„êµ¬ ì´ë¦„ì„ ì•„ëŠ”ì§€ í™•ì¸ (ì‹¤ì œë¡œëŠ” list_tools ê²°ê³¼ë¥¼ ìºì‹œí•´ì•¼ íš¨ìœ¨ì )
                server_tools_response = await session.list_tools()
                if any(t.name == tool_name for t in server_tools_response.tools):
                    target_session = session
                    break
            except Exception:
                continue # ì˜¤ë¥˜ê°€ ë°œìƒí•œ ì„¸ì…˜ì€ ê±´ë„ˆëœ€
        
        if not target_session:
            return f"ì˜¤ë¥˜: ë„êµ¬ '{tool_name}'ì„(ë¥¼) ì œê³µí•˜ëŠ” ì„œë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            tool_args = json.loads(tool_call.function.arguments)
            print(f"ë„êµ¬ í˜¸ì¶œ: {tool_name}, ì¸ì: {tool_args}")

            call_result = await target_session.call_tool(tool_name, tool_args)
            # ì„œë²„ë¡œë¶€í„° ë°›ì€ ì›ë³¸ ê²°ê³¼ê°€ ë¬´ì—‡ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            print(f"DEBUG: ì„œë²„ë¡œë¶€í„° ë°›ì€ ì›ë³¸ ê²°ê³¼: {call_result!r}")
            
            result_text = " ".join(
                content.text for content in call_result.content if isinstance(content, TextContent)
            )
            print(f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼: {result_text}")
            return result_text
        except Exception as e:
            error_msg = f"ì˜¤ë¥˜: ë„êµ¬ '{tool_name}' ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}"
            print(error_msg)
            return error_msg

    def _format_tool_for_openai(self, tool: MCPTool) -> Dict[str, Any]:
        """MCP Tool ê°ì²´ë¥¼ OpenAI API í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        return {
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema,
            },
        }
        
    async def close(self):
        """í™œì„±í™”ëœ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        print("ëª¨ë“  MCP ì„œë²„ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        await self.exit_stack.aclose()
        self.sessions.clear()

# ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë¥¼ ìœ„í•œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¡œì§ (ì£¼ë¡œ ë””ë²„ê¹…ìš©)
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)"""
    from dotenv import load_dotenv
    load_dotenv()
    
    agent_config = {
        "api_key": os.getenv("OPENAI_API_KEY"),
        "model_name": os.getenv("OPENAI_MODEL_NAME", "gpt-4o"),
    }
    
    if not agent_config["api_key"]:
        print("âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    agent = OpenaiMcpAgentStandard(config=agent_config)
    await agent.connect_to_servers()
    
    try:
        while True:
            query = input("\nğŸ‘¤ ì‚¬ìš©ì: ").strip()
            if query.lower() in ["exit", "quit"]:
                break
            response = await agent.run_query(query)
            print(f"ğŸ¤– AI: {response}")
    finally:
        await agent.close()

if __name__ == "__main__":
    asyncio.run(main()) 