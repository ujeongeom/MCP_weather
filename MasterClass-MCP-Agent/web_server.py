#!/usr/bin/env python3
"""
Web Server for OpenAI MCP Agent
OpenAI Agents SDK MCP Extensionì„ ì‚¬ìš©í•˜ëŠ” ì›¹ ì„œë²„
"""

import asyncio
import json
import logging
import os
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from dotenv import load_dotenv

# Import our OpenAI MCP Agent
from openai_mcp_agent import OpenAIMCPAgent
from openai_mcp_agent_standard import OpenaiMcpAgentStandard

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("web_server")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìƒëª…ì£¼ê¸° ì´ë²¤íŠ¸ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    ì„œë²„ ì‹œì‘ ì‹œ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³ , ì¢…ë£Œ ì‹œ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    agent_type = os.getenv("AGENT_TYPE", "AZURE").upper()
    logger.info(f"ğŸš€ ì„œë²„ ì‹œì‘, AI Agent ì´ˆê¸°í™” ì¤‘... (Agent Type: {agent_type})")

    agent = None
    if agent_type == "AZURE":
        agent_config = {
            "api_key": os.getenv("AZURE_OPENAI_API_KEY"),
            "azure_endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
            "api_version": os.getenv("AZURE_OPENAI_API_VERSION"),
            "model_name": os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4o"),
        }
        if not all(agent_config.values()):
            logger.error("âŒ AZURE ëª¨ë“œì— í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env íŒŒì¼ í™•ì¸: AZURE_OPENAI_...)")
        else:
            agent = OpenAIMCPAgent(config=agent_config)

    elif agent_type == "STANDARD":
        agent_config = {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model_name": os.getenv("OPENAI_MODEL_NAME", "gpt-4o"),
        }
        if not agent_config["api_key"]:
            logger.error("âŒ STANDARD ëª¨ë“œì— í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            agent = OpenaiMcpAgentStandard(config=agent_config)

    else:
        logger.error(f"âŒ ì˜ëª»ëœ AGENT_TYPE: '{agent_type}'. 'AZURE' ë˜ëŠ” 'STANDARD' ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

    if agent:
        try:
            # mcp_servers.json íŒŒì¼ì„ ì½ì–´ ëª¨ë“  ì„œë²„ì— ì—°ê²°
            await agent.connect_to_servers("mcp_servers.json")
            logger.info("âœ… AI Agent ì´ˆê¸°í™” ë° MCP ì„œë²„ ì—°ê²° ì™„ë£Œ.")
        except Exception as e:
            logger.error(f"âŒ AI Agent ì´ˆê¸°í™” ë˜ëŠ” MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}", exc_info=True)
            agent = None # ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •

    app.state.agent = agent
    
    yield # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ
    if app.state.agent:
        logger.info("ğŸ”Œ ì„œë²„ ì¢…ë£Œ, AI Agent ì—°ê²°ì„ í•´ì œí•©ë‹ˆë‹¤...")
        await app.state.agent.close()
        logger.info("âœ… AI Agent ì—°ê²° í•´ì œ ì™„ë£Œ.")

# FastAPI app
app = FastAPI(title="OpenAI MCP Agent Web Interface", lifespan=lifespan)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global OpenAI MCP Agent instance
openai_agent: Optional[OpenAIMCPAgent] = None

# Connected WebSocket clients
connected_clients: List[WebSocket] = []

# Request/Response models
class QueryRequest(BaseModel):
    message: str
    stream: bool = False

class MemoryRequest(BaseModel):
    content: str
    category: str = "general"

# ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ (HTML, CSS, JS)
static_dir = Path(__file__).parent / "static"
app.mount("/static", StaticFiles(directory=static_dir), name="static")
templates = Jinja2Templates(directory=static_dir)

@app.get("/", response_class=HTMLResponse)
async def get_root(request: Request):
    """ë©”ì¸ HTML í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    return templates.TemplateResponse("index.html", {"request": request})

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """ì›¹ì†Œì¼“ì„ í†µí•´ í´ë¼ì´ì–¸íŠ¸ì™€ ì‹¤ì‹œê°„ í†µì‹ ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    await websocket.accept()
    connected_clients.append(websocket)
    logger.info(f"ğŸ”— í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {websocket.client.host}")
    
    agent: OpenAIMCPAgent | OpenaiMcpAgentStandard = websocket.app.state.agent
    
    if not agent:
        error_message = "AI ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        logger.error(f"ì›¹ì†Œì¼“ ì—°ê²° ì˜¤ë¥˜: {error_message}")
        await websocket.send_json({"type": "error", "data": error_message})
        await websocket.close()
        connected_clients.remove(websocket)
        return

    try:
        await websocket.send_json({
            "type": "connection",
            "message": "ğŸ¤– OpenAI MCP Agentì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!",
            "timestamp": datetime.now().isoformat()
        })
        
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            if message.get("type") == "query":
                query = message.get("message", "")
                logger.info(f"ğŸ“© ì¿¼ë¦¬ ìˆ˜ì‹ : {query}")
                
                response_text = await agent.run_query(query)
                
                await websocket.send_json({
                    "type": "response",
                    "message": response_text,
                    "timestamp": datetime.now().isoformat()
                })
                logger.info(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡: {response_text[:80]}...")

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€: {websocket.client.host}")
    except Exception as e:
        logger.error(f"âŒ ì›¹ì†Œì¼“ ì˜¤ë¥˜: {e}", exc_info=True)
        try:
            await websocket.send_json({
                "type": "error",
                "message": f"ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                "timestamp": datetime.now().isoformat()
            })
        except Exception:
            pass
    finally:
        if websocket in connected_clients:
            connected_clients.remove(websocket)

# REST API endpoints
@app.post("/api/query")
async def query_agent(request: QueryRequest):
    """Process a query through the AI agent"""
    try:
        if not openai_agent:
            raise HTTPException(status_code=500, detail="OpenAI MCP Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = await openai_agent.query(request.message, stream=request.stream)
        
        # Broadcast to WebSocket clients
        await broadcast_to_clients({
            "type": "activity",
            "message": f"Query processed: {request.message[:50]}...",
            "timestamp": datetime.now().isoformat()
        })
        
        return {
            "success": True,
            "response": response,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Query error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/tools")
async def list_tools():
    """ëª¨ë“  MCP ì„œë²„ì˜ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
    agent = app.state.agent
    if not agent or not hasattr(agent, "sessions"):
        return {"tools": []}
    all_tools = []
    for server_name, session in agent.sessions.items():
        try:
            tools_response = await session.list_tools()
            for t in tools_response.tools:
                all_tools.append({
                    "name": t.name,
                    "description": t.description,
                    "server": server_name
                })
        except Exception:
            continue
    return {"tools": all_tools}

@app.post("/api/memory")
async def add_memory(request: MemoryRequest):
    """Add content to memory"""
    try:
        if not openai_agent:
            raise HTTPException(status_code=500, detail="OpenAI MCP Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # OpenAI MCP Agentì˜ ë‚´ë¶€ ë©”ëª¨ë¦¬ ì‚¬ìš©
        result = await openai_agent._add_to_memory(request.content, request.category)
        
        return {
            "success": True,
            "message": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Add memory error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/memory")
async def get_memory():
    """Get conversation memory"""
    try:
        if not openai_agent:
            raise HTTPException(status_code=500, detail="OpenAI MCP Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        memory = openai_agent.get_memory()
        
        return {
            "success": True,
            "memory": memory,
            "count": len(memory),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Get memory error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/memory")
async def clear_memory():
    """Clear conversation memory"""
    try:
        if not openai_agent:
            raise HTTPException(status_code=500, detail="OpenAI MCP Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        result = openai_agent.clear_memory()
        
        return {
            "success": True,
            "message": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Clear memory error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/status")
async def get_status():
    """Get system status"""
    try:
        agent_ready = openai_agent is not None
        memory_count = len(openai_agent.get_memory()) if openai_agent else 0
        
        # MCP ì„œë²„ ìƒíƒœ (ì„¤ì • íŒŒì¼ì—ì„œ ì½ê¸°)
        mcp_servers = ["weather", "example"]  # mcp_agent.config.yamlì—ì„œ ì •ì˜ëœ ì„œë²„ë“¤
        
        return {
            "success": True,
            "status": {
                "agent_ready": agent_ready,
                "agent_type": "OpenAI MCP Agent",
                "mcp_servers": mcp_servers,
                "memory_items": memory_count,
                "websocket_clients": len(connected_clients),
                "timestamp": datetime.now().isoformat()
            }
        }
    except Exception as e:
        logger.error(f"Status error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/config")
async def get_config():
    """Get MCP configuration"""
    try:
        # OpenAI ì„¤ì • í™•ì¸
        azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
        azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
        azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
        openai_api_key = os.getenv("OPENAI_API_KEY")
        
        # ì„¤ì • ìƒíƒœ í™•ì¸
        if azure_api_key and azure_endpoint and azure_api_version:
            provider = "Azure OpenAI"
            model = azure_deployment or "gpt-4o-mini"
            endpoint_info = azure_endpoint
            api_version = azure_api_version
        elif openai_api_key:
            provider = "OpenAI"
            model = "gpt-4o-mini"
            endpoint_info = "api.openai.com"
            api_version = "N/A"
        else:
            provider = "ë¯¸ì„¤ì •"
            model = "ë¯¸ì„¤ì •"
            endpoint_info = "ë¯¸ì„¤ì •"
            api_version = "ë¯¸ì„¤ì •"
        
        config_info = {
            "mcp_config_file": "mcp_agent.config.yaml",
            "secrets_file": "mcp_agent.secrets.yaml", 
            "configured_servers": ["weather", "example"],
            "model_provider": provider,
            "model": model,
            "endpoint": endpoint_info,
            "api_version": api_version,
            "azure_configured": bool(azure_api_key and azure_endpoint and azure_api_version),
            "openai_configured": bool(openai_api_key)
        }
        
        return {
            "success": True,
            "config": config_info,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Config error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ë‹¨ìˆœí™”ëœ ì—”ë“œí¬ì¸íŠ¸ë“¤ (OpenAI Agents SDKê°€ MCP ì„œë²„ë¥¼ ìë™ ê´€ë¦¬)
@app.get("/api/servers")
async def list_servers():
    """ì—°ê²°ëœ MCP ì„œë²„ ëª©ë¡ ë°˜í™˜"""
    agent = app.state.agent
    if not agent or not hasattr(agent, "sessions"):
        return {"servers": []}
    return {"servers": list(agent.sessions.keys())}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    agent_status = "OK" if app.state.agent and app.state.agent.session else "Unavailable"
    return {
        "status": "ok",
        "agent_status": agent_status,
        "connected_clients": len(connected_clients)
    }

def main():
    """ì›¹ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    logger.info(f"ğŸŒ http://127.0.0.1:{port} ì—ì„œ ì›¹ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main() 